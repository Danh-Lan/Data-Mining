{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":63689,"databundleVersionId":6985693,"sourceType":"competition"},{"sourceId":6899377,"sourceType":"datasetVersion","datasetId":3963175}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.feature_selection import RFE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.inspection import PartialDependenceDisplay","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-03T15:55:04.834706Z","iopub.execute_input":"2023-12-03T15:55:04.835715Z","iopub.status.idle":"2023-12-03T15:55:07.811082Z","shell.execute_reply.started":"2023-12-03T15:55:04.835677Z","shell.execute_reply":"2023-12-03T15:55:07.809091Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:05:11.442775Z","iopub.execute_input":"2023-12-03T16:05:11.443271Z","iopub.status.idle":"2023-12-03T16:05:11.461612Z","shell.execute_reply.started":"2023-12-03T16:05:11.443239Z","shell.execute_reply":"2023-12-03T16:05:11.460056Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/projetdm-data/TRAIN.CSV\n/kaggle/input/projetdm-data/TEST.CSV\n/kaggle/input/the-instarcraft-2-player-prediction-challenge/TRAIN_LONG.CSV.GZ\n/kaggle/input/the-instarcraft-2-player-prediction-challenge/SAMPLE_SUBMISSION.CSV\n/kaggle/input/the-instarcraft-2-player-prediction-challenge/TRAIN.CSV.GZ\n/kaggle/input/the-instarcraft-2-player-prediction-challenge/TEST_LONG.CSV.GZ\n/kaggle/input/the-instarcraft-2-player-prediction-challenge/TEST.CSV.GZ\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = \"/kaggle/input/projetdm-data/TRAIN.CSV\"\n### Loop the data lines\nwith open(train_data, 'r') as temp_f:\n    # get No of columns in each line\n    col_count = [ len(l.split(\",\")) for l in temp_f.readlines() ]\n\n### Generate column names  (names will be 0, 1, 2, ..., maximum columns - 1)\ncolumn_names = [i for i in range(0, max(col_count))]\ndf_train = pd.read_csv(train_data,header=None, delimiter=\",\", names=column_names, low_memory=False).astype(str)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:05:14.041484Z","iopub.execute_input":"2023-12-03T16:05:14.041847Z","iopub.status.idle":"2023-12-03T16:05:21.561598Z","shell.execute_reply.started":"2023-12-03T16:05:14.041821Z","shell.execute_reply":"2023-12-03T16:05:21.560602Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                  0        1     2     3      \\\n0     http://eu.battle.net/sc2/en/profile/4234852/1/...  Protoss  Base     s   \n1     http://eu.battle.net/sc2/en/profile/3074362/1/...  Protoss     s  Base   \n2     http://eu.battle.net/sc2/en/profile/4234852/1/...  Protoss  Base     s   \n3     http://eu.battle.net/sc2/en/profile/3074362/1/...  Protoss  Base     s   \n4     http://eu.battle.net/sc2/en/profile/4234852/1/...  Protoss  Base     s   \n...                                                 ...      ...   ...   ...   \n3047     http://xx.battle.net/sc2/en/profile/405/1/MMA/   Terran     s     s   \n3048  http://xx.battle.net/sc2/en/profile/410/1/STBo...   Terran     s     s   \n3049     http://xx.battle.net/sc2/en/profile/405/1/MMA/   Terran     s     s   \n3050  http://xx.battle.net/sc2/en/profile/410/1/STBo...   Terran     s     s   \n3051     http://xx.battle.net/sc2/en/profile/405/1/MMA/   Terran     s     s   \n\n         4         5         6         7         8         9      ... 10529  \\\n0            s         s         s         s        t5      Base  ...   nan   \n1            s         s      Base         s         s      Base  ...   nan   \n2            s         s      Base         s  hotkey30  hotkey00  ...   nan   \n3            s      Base         s         s         s        t5  ...   nan   \n4            s         s      Base         s  hotkey30  hotkey00  ...   nan   \n...        ...       ...       ...       ...       ...       ...  ...   ...   \n3047         s         s         s  hotkey10  hotkey20  hotkey30  ...   nan   \n3048  hotkey10         s  hotkey20         s         s  hotkey12  ...   nan   \n3049         s  hotkey10  hotkey20  hotkey30  hotkey40  hotkey50  ...   nan   \n3050  hotkey10         s  hotkey20         s         s  hotkey12  ...   nan   \n3051         s  hotkey10  hotkey20  hotkey30  hotkey40  hotkey50  ...   nan   \n\n     10530 10531 10532 10533 10534 10535 10536 10537 10538  \n0      nan   nan   nan   nan   nan   nan   nan   nan   nan  \n1      nan   nan   nan   nan   nan   nan   nan   nan   nan  \n2      nan   nan   nan   nan   nan   nan   nan   nan   nan  \n3      nan   nan   nan   nan   nan   nan   nan   nan   nan  \n4      nan   nan   nan   nan   nan   nan   nan   nan   nan  \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n3047   nan   nan   nan   nan   nan   nan   nan   nan   nan  \n3048   nan   nan   nan   nan   nan   nan   nan   nan   nan  \n3049   nan   nan   nan   nan   nan   nan   nan   nan   nan  \n3050   nan   nan   nan   nan   nan   nan   nan   nan   nan  \n3051   nan   nan   nan   nan   nan   nan   nan   nan   nan  \n\n[3052 rows x 10539 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>10529</th>\n      <th>10530</th>\n      <th>10531</th>\n      <th>10532</th>\n      <th>10533</th>\n      <th>10534</th>\n      <th>10535</th>\n      <th>10536</th>\n      <th>10537</th>\n      <th>10538</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://eu.battle.net/sc2/en/profile/4234852/1/...</td>\n      <td>Protoss</td>\n      <td>Base</td>\n      <td>s</td>\n      <td>s</td>\n      <td>s</td>\n      <td>s</td>\n      <td>s</td>\n      <td>t5</td>\n      <td>Base</td>\n      <td>...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://eu.battle.net/sc2/en/profile/3074362/1/...</td>\n      <td>Protoss</td>\n      <td>s</td>\n      <td>Base</td>\n      <td>s</td>\n      <td>s</td>\n      <td>Base</td>\n      <td>s</td>\n      <td>s</td>\n      <td>Base</td>\n      <td>...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://eu.battle.net/sc2/en/profile/4234852/1/...</td>\n      <td>Protoss</td>\n      <td>Base</td>\n      <td>s</td>\n      <td>s</td>\n      <td>s</td>\n      <td>Base</td>\n      <td>s</td>\n      <td>hotkey30</td>\n      <td>hotkey00</td>\n      <td>...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://eu.battle.net/sc2/en/profile/3074362/1/...</td>\n      <td>Protoss</td>\n      <td>Base</td>\n      <td>s</td>\n      <td>s</td>\n      <td>Base</td>\n      <td>s</td>\n      <td>s</td>\n      <td>s</td>\n      <td>t5</td>\n      <td>...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://eu.battle.net/sc2/en/profile/4234852/1/...</td>\n      <td>Protoss</td>\n      <td>Base</td>\n      <td>s</td>\n      <td>s</td>\n      <td>s</td>\n      <td>Base</td>\n      <td>s</td>\n      <td>hotkey30</td>\n      <td>hotkey00</td>\n      <td>...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3047</th>\n      <td>http://xx.battle.net/sc2/en/profile/405/1/MMA/</td>\n      <td>Terran</td>\n      <td>s</td>\n      <td>s</td>\n      <td>s</td>\n      <td>s</td>\n      <td>s</td>\n      <td>hotkey10</td>\n      <td>hotkey20</td>\n      <td>hotkey30</td>\n      <td>...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>3048</th>\n      <td>http://xx.battle.net/sc2/en/profile/410/1/STBo...</td>\n      <td>Terran</td>\n      <td>s</td>\n      <td>s</td>\n      <td>hotkey10</td>\n      <td>s</td>\n      <td>hotkey20</td>\n      <td>s</td>\n      <td>s</td>\n      <td>hotkey12</td>\n      <td>...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>3049</th>\n      <td>http://xx.battle.net/sc2/en/profile/405/1/MMA/</td>\n      <td>Terran</td>\n      <td>s</td>\n      <td>s</td>\n      <td>s</td>\n      <td>hotkey10</td>\n      <td>hotkey20</td>\n      <td>hotkey30</td>\n      <td>hotkey40</td>\n      <td>hotkey50</td>\n      <td>...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>3050</th>\n      <td>http://xx.battle.net/sc2/en/profile/410/1/STBo...</td>\n      <td>Terran</td>\n      <td>s</td>\n      <td>s</td>\n      <td>hotkey10</td>\n      <td>s</td>\n      <td>hotkey20</td>\n      <td>s</td>\n      <td>s</td>\n      <td>hotkey12</td>\n      <td>...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>3051</th>\n      <td>http://xx.battle.net/sc2/en/profile/405/1/MMA/</td>\n      <td>Terran</td>\n      <td>s</td>\n      <td>s</td>\n      <td>s</td>\n      <td>hotkey10</td>\n      <td>hotkey20</td>\n      <td>hotkey30</td>\n      <td>hotkey40</td>\n      <td>hotkey50</td>\n      <td>...</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n  </tbody>\n</table>\n<p>3052 rows × 10539 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import re\nhotkey_actions_to_count = [\"0\",\"1\",\"2\"]\nhotkeys_to_count = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\nwindow_size = 3","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:01:23.410074Z","iopub.execute_input":"2023-12-02T21:01:23.410540Z","iopub.status.idle":"2023-12-02T21:01:23.417315Z","shell.execute_reply.started":"2023-12-02T21:01:23.410503Z","shell.execute_reply":"2023-12-02T21:01:23.416043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cut_off: take at most the first cut_off second from every game, default 6 minutes\n# min_game_length: remove too short games, isn't applied if is_Test is True, default 1 minute\n\ndef extract_features(input_data, is_test = False, cut_off = 6*60, min_game_length = 1*60):\n    output_data = []\n    for row in input_data:\n        count_hotkey_actions = [0] * len(hotkey_actions_to_count)\n        count_hotkeys = [0] * len(hotkeys_to_count)\n        new_row = []\n        new_row.append(row[0])\n        new_row.append(row[1])\n        game_length = 0\n        count_action = 0\n        count_pattern_3_hotkey = 0\n        count_pattern_3s = 0\n        count_pattern_hsh = 0\n        \n        for action in row[2:]:\n            # look for time cell, begin with \"t\"\n            if isinstance(action, str):\n                match = re.match(r't(\\d+)', action)\n                if match:\n                    time = int(match.group(1))\n                    game_length = time\n                    if (game_length > cut_off):\n                        break\n\n            # count 0, 1, 2 at the end of \"hotkey\"\n            for index, substring in enumerate(hotkey_actions_to_count):\n                if (action.startswith('hotkey') and action.endswith(substring)):\n                    count_hotkey_actions[index] += 1\n\n            # count hotkey\n            for index, substring in enumerate(hotkeys_to_count):\n                if (action.startswith('hotkey') and action[-2] == substring):\n                    count_hotkeys[index] += 1\n            \n            if (action == 's' or action == 'Base'):\n                count_action += 1\n            \n        # there may be more action after the last 't'\n        game_length += 2\n            \n        # frenquency of base, mineral, other action\n        count_action /= game_length\n        new_row.append(count_action)\n        \n        for i in range(2, len(row) - window_size + 1):\n            actions_in_window = row[i:i+window_size]\n            all_start_with_s = all(action.startswith('s') for action in actions_in_window)\n            if all_start_with_s:\n                count_pattern_3s += 1\n            if actions_in_window[0].startswith('hotkey') and actions_in_window[2].startswith('hotkey'):\n                if actions_in_window[1].startswith('s'):\n                    count_pattern_hsh += 1\n                elif actions_in_window[1].startswith('hotkey'):\n                    count_pattern_3_hotkey += 1\n        \n        # frequency of 3-hotkey pattern\n        count_pattern_3_hotkey /= game_length\n        new_row.append(count_pattern_3_hotkey)\n        \n        #frequency of 3s pattern\n        count_pattern_3s /= game_length\n        new_row.append(count_pattern_3s) \n        \n        #frequency of hotkey - s - hotkey pattern\n        count_pattern_hsh /= game_length\n        new_row.append(count_pattern_hsh) \n        \n        \n        # Calculate the frequency of hotkey\n        for i in range(len(hotkey_actions_to_count)):\n            count_hotkey_actions[i] /= game_length\n\n        for i in range(len(hotkeys_to_count)):\n            count_hotkeys[i] /= game_length\n        \n        for i in range(len(count_hotkey_actions)):\n            new_row.append(count_hotkey_actions[i])\n        for i in range(len(count_hotkeys)):\n            new_row.append(count_hotkeys[i])\n            \n        if (is_test == False):\n            if (game_length > min_game_length):\n                output_data.append(new_row)\n        else:\n            output_data.append(new_row)\n    return output_data","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:01:24.894026Z","iopub.execute_input":"2023-12-02T21:01:24.894642Z","iopub.status.idle":"2023-12-02T21:01:24.913620Z","shell.execute_reply.started":"2023-12-02T21:01:24.894610Z","shell.execute_reply":"2023-12-02T21:01:24.912527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"converted_train_data = df_train.values\noutput_train_data = extract_features(converted_train_data)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:01:30.575862Z","iopub.execute_input":"2023-12-02T21:01:30.576377Z","iopub.status.idle":"2023-12-02T21:03:17.363228Z","shell.execute_reply.started":"2023-12-02T21:01:30.576336Z","shell.execute_reply":"2023-12-02T21:03:17.361919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the table to a DataFrame with headers\nheaders = ['url', 'race', 'action', 'pattern_3_hotkey', 'pattern_3s', 'pattern_hsh', 'hotkey_created', 'hotkey_update', 'hotkey_used',\n          'key0','key1', 'key2', 'key3', 'key4', 'key5', 'key6',\n          'key7', 'key8', 'key9']\nnew_df = pd.DataFrame(output_train_data, columns=headers)\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:03:17.365245Z","iopub.execute_input":"2023-12-02T21:03:17.365616Z","iopub.status.idle":"2023-12-02T21:03:17.407144Z","shell.execute_reply.started":"2023-12-02T21:03:17.365588Z","shell.execute_reply":"2023-12-02T21:03:17.405584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data visualization\n# Histograms\n\nnew_df.hist(bins=15, color='steelblue', edgecolor='black', linewidth=1.0,\n           xlabelsize=8, ylabelsize=8, grid=False)    \nplt.tight_layout(rect=(0, 0, 1.2, 1.2))","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:03:50.494320Z","iopub.execute_input":"2023-12-02T21:03:50.494730Z","iopub.status.idle":"2023-12-02T21:03:54.733092Z","shell.execute_reply.started":"2023-12-02T21:03:50.494699Z","shell.execute_reply":"2023-12-02T21:03:54.731783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bar Plot\nfig = plt.figure(figsize = (6, 4))\ntitle = fig.suptitle(\"Base Frequency\", fontsize=14)\nfig.subplots_adjust(top=0.85, wspace=0.3)\n\nax = fig.add_subplot(1,1, 1)\nax.set_xlabel(\"Base\")\nax.set_ylabel(\"Frequency\") \nw_q = new_df['race'].value_counts()\nw_q = (list(w_q.index), list(w_q.values))\nax.tick_params(axis='both', which='major', labelsize=8.5)\nbar = ax.bar(w_q[0], w_q[1], color='steelblue', \n        edgecolor='black', linewidth=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:08:54.622321Z","iopub.execute_input":"2023-12-02T21:08:54.622917Z","iopub.status.idle":"2023-12-02T21:08:54.871079Z","shell.execute_reply.started":"2023-12-02T21:08:54.622870Z","shell.execute_reply":"2023-12-02T21:08:54.869835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pair-wise Scatter Plots\ncols = ['action', 'pattern_3s','hotkey_used', 'key2', \"key3\",\"key4\",\"race\"]\npp = sns.pairplot(new_df[cols], hue = \"race\", height=1.8, aspect=1.8,\n                  plot_kws=dict(edgecolor=\"k\", linewidth=0.5),\n                  diag_kind=\"kde\", diag_kws=dict(fill=True))\n\nfig = pp.fig \nfig.subplots_adjust(top=0.93, wspace=0.3)\nt = fig.suptitle('Key Attributes Pairwise Plots', fontsize=14)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:09:03.488026Z","iopub.execute_input":"2023-12-02T21:09:03.488477Z","iopub.status.idle":"2023-12-02T21:09:29.969113Z","shell.execute_reply.started":"2023-12-02T21:09:03.488443Z","shell.execute_reply":"2023-12-02T21:09:29.968183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One-hot encode the specified columns\nnew_df = pd.get_dummies(new_df, columns=['race'])","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:09:53.294757Z","iopub.execute_input":"2023-12-02T21:09:53.295258Z","iopub.status.idle":"2023-12-02T21:09:53.306624Z","shell.execute_reply.started":"2023-12-02T21:09:53.295221Z","shell.execute_reply":"2023-12-02T21:09:53.305400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation matrix\ncorrelation_matrix = new_df.iloc[:, 1:].corr(method='spearman')\n# Create a heatmap using seaborn\nplt.figure(figsize=(12, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title('Correlation Matrix Heatmap')\n# Save the figure\nplt.savefig('correlation_matrix.png') \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:14:09.675435Z","iopub.execute_input":"2023-12-02T21:14:09.675963Z","iopub.status.idle":"2023-12-02T21:14:12.213899Z","shell.execute_reply.started":"2023-12-02T21:14:09.675925Z","shell.execute_reply":"2023-12-02T21:14:12.212933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X, y separation\nX = new_df.iloc[:, 1:]  # Features (game information)\ny = new_df.iloc[:, 0]   # Target variable (player's URL)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:17:58.672769Z","iopub.execute_input":"2023-12-02T21:17:58.674229Z","iopub.status.idle":"2023-12-02T21:17:58.683981Z","shell.execute_reply.started":"2023-12-02T21:17:58.674176Z","shell.execute_reply":"2023-12-02T21:17:58.681233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply PCA to calculate explained variance\npca = PCA()\nX_pca = pca.fit_transform(X)\n\n# Proportion of variance explained by each principal component\nexplained_variance_ratio = pca.explained_variance_ratio_\n\n# Create a DataFrame to display the results\ndf_explained_variance = pd.DataFrame({'Explained Variance Ratio': explained_variance_ratio})\ndf_explained_variance.index = [f'PC{i+1}' for i in range(len(explained_variance_ratio))]\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:18:01.901121Z","iopub.execute_input":"2023-12-02T21:18:01.901509Z","iopub.status.idle":"2023-12-02T21:18:01.942661Z","shell.execute_reply.started":"2023-12-02T21:18:01.901482Z","shell.execute_reply":"2023-12-02T21:18:01.940912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the scree plot\nplt.figure(figsize=(8, 6))\nplt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o')\nplt.title('Scree Plot of Explained Variance')\nplt.xlabel('Principal Components')\nplt.ylabel('Explained Variance Ratio')\nplt.xticks(range(1, len(explained_variance_ratio) + 1))\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:18:10.191454Z","iopub.execute_input":"2023-12-02T21:18:10.191931Z","iopub.status.idle":"2023-12-02T21:18:10.620302Z","shell.execute_reply.started":"2023-12-02T21:18:10.191892Z","shell.execute_reply":"2023-12-02T21:18:10.619073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame for plotting\ndf_pca = pd.DataFrame(data=X_pca[:, :2], columns=['PC1', 'PC2'])\ndf_pca['Target'] = y\n\n# Visualize the reduced data using a scatterplot\nplt.figure(figsize=(8, 6))\ntargets = list(set(y))\n\nfor target in targets:\n    indices_to_keep = df_pca['Target'] == target\n    plt.scatter(df_pca.loc[indices_to_keep, 'PC1'],\n                df_pca.loc[indices_to_keep, 'PC2'],\n                label=target)\n\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.title('PCA Visualization')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:18:17.673632Z","iopub.execute_input":"2023-12-02T21:18:17.674158Z","iopub.status.idle":"2023-12-02T21:18:20.596758Z","shell.execute_reply.started":"2023-12-02T21:18:17.674115Z","shell.execute_reply":"2023-12-02T21:18:20.595533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply LDA for dimensionality reduction (specify the desired number of components)\nlda = LinearDiscriminantAnalysis()\nX_lda = lda.fit_transform(X, y)\n\n# Display the reduced dimensions\nprint(f\"Original shape: {X.shape}\")\nprint(f\"Reduced shape: {X_lda.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:19:48.394538Z","iopub.execute_input":"2023-12-02T21:19:48.395038Z","iopub.status.idle":"2023-12-02T21:19:48.489018Z","shell.execute_reply.started":"2023-12-02T21:19:48.395003Z","shell.execute_reply":"2023-12-02T21:19:48.487344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame for plotting\ndf_lda = pd.DataFrame(data=X_lda[:, :2], columns=['LDA1', 'LDA2'])\ndf_lda['Target'] = y\n\n# Visualize the reduced data using a scatterplot\nplt.figure(figsize=(8, 6))\ntargets = list(set(y))\n\nfor target in targets:\n    indices_to_keep = df_pca['Target'] == target\n    plt.scatter(df_lda.loc[indices_to_keep, 'LDA1'],\n                df_lda.loc[indices_to_keep, 'LDA2'],\n                label=target)\n\nplt.xlabel('1st dimension')\nplt.ylabel('2nd dimension')\nplt.title('LDA Visualization')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:29:05.547246Z","iopub.execute_input":"2023-12-02T21:29:05.547712Z","iopub.status.idle":"2023-12-02T21:29:08.341419Z","shell.execute_reply.started":"2023-12-02T21:29:05.547680Z","shell.execute_reply":"2023-12-02T21:29:08.340393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KNN on LDA\n# Split the data into training and testing sets\nX_train, X_valid, y_train, y_valid = train_test_split(X_lda, y, test_size=0.2, random_state=42)\n\n# Train a classifier (K-Nearest Neighbors in this example)\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train, y_train)\n\n# Make predictions\ny_pred = knn.predict(X_valid)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:14:22.201054Z","iopub.execute_input":"2023-12-01T11:14:22.201593Z","iopub.status.idle":"2023-12-01T11:14:22.271675Z","shell.execute_reply.started":"2023-12-01T11:14:22.201557Z","shell.execute_reply":"2023-12-01T11:14:22.270171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest\n# Split the data into training and testing sets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)  # You can adjust the test_size\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:40:51.937043Z","iopub.execute_input":"2023-12-02T21:40:51.937493Z","iopub.status.idle":"2023-12-02T21:40:51.946856Z","shell.execute_reply.started":"2023-12-02T21:40:51.937462Z","shell.execute_reply":"2023-12-02T21:40:51.945914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom scipy.stats import randint\nfrom sklearn.metrics import make_scorer, f1_score\n\n# Define the parameter distributions for random search\nparam_dist = {\n    'n_estimators': randint(50, 150),\n    'max_depth': [None, 10, 20],\n    'min_samples_split': randint(2, 10),\n    'min_samples_leaf': randint(1, 4)\n}\n\n# Create a Random Forest model\nrf_model = RandomForestClassifier(random_state=42)\n\n# Perform random search with 5-fold cross-validation\nrandom_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, cv=5, scoring='f1_macro', n_iter=40, random_state=42, n_jobs=4)\nrandom_search.fit(X_train, y_train)\n\n# Print the best hyperparameters\nprint(\"Best Hyperparameters:\", random_search.best_params_)\n\n# Evaluate the model on the test set\nbest_rf_model = random_search.best_estimator_\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:40:55.247895Z","iopub.execute_input":"2023-12-02T21:40:55.248781Z","iopub.status.idle":"2023-12-02T21:42:47.618640Z","shell.execute_reply.started":"2023-12-02T21:40:55.248738Z","shell.execute_reply":"2023-12-02T21:42:47.617455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optimal Random Forest model\noptimal_rf_model = RandomForestClassifier(max_depth=20, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 88, random_state = 42)\noptimal_rf_model.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:44:01.993111Z","iopub.execute_input":"2023-12-02T21:44:01.993682Z","iopub.status.idle":"2023-12-02T21:44:03.910707Z","shell.execute_reply.started":"2023-12-02T21:44:01.993621Z","shell.execute_reply":"2023-12-02T21:44:03.909820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = optimal_rf_model.predict(X_valid)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:44:07.717669Z","iopub.execute_input":"2023-12-02T21:44:07.719018Z","iopub.status.idle":"2023-12-02T21:44:07.788696Z","shell.execute_reply.started":"2023-12-02T21:44:07.718973Z","shell.execute_reply":"2023-12-02T21:44:07.787319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the F1 score\nf1 = f1_score(y_valid, y_pred, average= 'macro')\n\n# Print the F1 score\nprint(f1)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:44:09.994710Z","iopub.execute_input":"2023-12-02T21:44:09.995201Z","iopub.status.idle":"2023-12-02T21:44:10.018137Z","shell.execute_reply.started":"2023-12-02T21:44:09.995163Z","shell.execute_reply":"2023-12-02T21:44:10.016718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature importances\nimportances = optimal_rf_model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in optimal_rf_model.estimators_], axis=0)\n\nfeature_names = list(X_train.columns)\nforest_importances = pd.Series(importances, index=feature_names)\nsorted_importances = forest_importances.sort_values(ascending = False)\nprint(sorted_importances)\n\nfig, ax = plt.subplots()\nsorted_importances.plot.bar(ax=ax)\nax.set_title(\"Feature importances using MDI\")\nax.set_ylabel(\"Mean decrease in impurity\")\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:44:14.349129Z","iopub.execute_input":"2023-12-02T21:44:14.349666Z","iopub.status.idle":"2023-12-02T21:44:14.977940Z","shell.execute_reply.started":"2023-12-02T21:44:14.349622Z","shell.execute_reply":"2023-12-02T21:44:14.976624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install treeinterpreter","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:49:12.802712Z","iopub.execute_input":"2023-12-02T21:49:12.803155Z","iopub.status.idle":"2023-12-02T21:49:28.770885Z","shell.execute_reply.started":"2023-12-02T21:49:12.803114Z","shell.execute_reply":"2023-12-02T21:49:28.769749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install waterfallcharts","metadata":{"execution":{"iopub.status.busy":"2023-12-02T21:54:33.143420Z","iopub.execute_input":"2023-12-02T21:54:33.143945Z","iopub.status.idle":"2023-12-02T21:54:50.169428Z","shell.execute_reply.started":"2023-12-02T21:54:33.143904Z","shell.execute_reply":"2023-12-02T21:54:50.167889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How decision was made\nfrom treeinterpreter import treeinterpreter\nfrom waterfall_chart import plot as waterfall\n\nprediction, bias, contributions = treeinterpreter.predict(optimal_rf_model, X_valid.values)\nprediction.shape, bias.shape, contributions.shape\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T22:20:46.494435Z","iopub.execute_input":"2023-12-02T22:20:46.495100Z","iopub.status.idle":"2023-12-02T22:20:51.872059Z","shell.execute_reply.started":"2023-12-02T22:20:46.495060Z","shell.execute_reply":"2023-12-02T22:20:51.870883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = lis(y)\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T22:43:00.443721Z","iopub.execute_input":"2023-12-02T22:43:00.444202Z","iopub.status.idle":"2023-12-02T22:43:00.455686Z","shell.execute_reply.started":"2023-12-02T22:43:00.444168Z","shell.execute_reply":"2023-12-02T22:43:00.454329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Organize the result into a DataFrame for better visualization\ncontrib_df = pd.DataFrame(contributions[0], columns=feature_names)\nresult_df = pd.DataFrame({'Prediction': prediction, 'Bias': bias})\nresult_df = pd.concat([result_df, contrib_df], axis=1)\n\nprint(result_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-12-02T22:35:54.313678Z","iopub.execute_input":"2023-12-02T22:35:54.314898Z","iopub.status.idle":"2023-12-02T22:35:55.192934Z","shell.execute_reply.started":"2023-12-02T22:35:54.314854Z","shell.execute_reply":"2023-12-02T22:35:55.190961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"contributions[0].shape","metadata":{"execution":{"iopub.status.busy":"2023-12-02T22:37:01.709510Z","iopub.execute_input":"2023-12-02T22:37:01.709991Z","iopub.status.idle":"2023-12-02T22:37:01.718651Z","shell.execute_reply.started":"2023-12-02T22:37:01.709952Z","shell.execute_reply":"2023-12-02T22:37:01.717506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Bias For Sample 0                        : %s\"%bias[0])\nprint(\"Constributions For Sample 0              : %s\"%contributions[0])\nprint(\"Prediction Based on Bias & Contributions : %.2f\"%np.argmax((bias[0] + contributions[0].sum(axis=0))))\nprint(\"Target Value As Per Treeinterpreter      : %.2f\"%np.argmax(prediction[0]))\nprint(y_pred[0])\nprint(y_valid[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-02T22:23:46.133925Z","iopub.execute_input":"2023-12-02T22:23:46.134373Z","iopub.status.idle":"2023-12-02T22:23:46.147019Z","shell.execute_reply.started":"2023-12-02T22:23:46.134342Z","shell.execute_reply":"2023-12-02T22:23:46.146100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(instances)):\n    print(\"Instance\", i)\n    print(\"Bias (trainset mean)\", biases[i])\n    print(\"Feature contributions:\")\n    for c, feature in sorted(zip(contributions[i], \n                                 feature_names), \n                             key=lambda x: -abs(x[0])):\n        print(feature, round(c, 2))\n    print(\"-\"*20 )","metadata":{"execution":{"iopub.status.busy":"2023-12-02T22:14:22.752874Z","iopub.execute_input":"2023-12-02T22:14:22.753345Z","iopub.status.idle":"2023-12-02T22:14:22.804514Z","shell.execute_reply.started":"2023-12-02T22:14:22.753311Z","shell.execute_reply":"2023-12-02T22:14:22.802908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row.values[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-01T18:46:54.950821Z","iopub.execute_input":"2023-12-01T18:46:54.951145Z","iopub.status.idle":"2023-12-01T18:46:54.957554Z","shell.execute_reply.started":"2023-12-01T18:46:54.951122Z","shell.execute_reply":"2023-12-01T18:46:54.956831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SVM\n# Standardize the features (optional but recommended for SVM)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_valid)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T14:09:45.203791Z","iopub.execute_input":"2023-11-20T14:09:45.204626Z","iopub.status.idle":"2023-11-20T14:09:45.223702Z","shell.execute_reply.started":"2023-11-20T14:09:45.204577Z","shell.execute_reply":"2023-11-20T14:09:45.222679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import loguniform\n# Define the SVM model\nsvm_model = SVC()\n\n# Define the parameter distributions for RandomizedSearchCV\nparam_dist = {\n    'C': loguniform(1e-3, 1e3),        # Regularization parameter\n    'kernel': ['linear', 'rbf', 'poly'],  # Kernel type\n    'gamma': ['scale', 'auto', 'scale'],  # Kernel coefficient for 'rbf' kernel\n    'degree': randint(2, 5),            # Degree for 'poly' kernel\n    'shrinking': [True, False],         # Whether to use the shrinking heuristic\n    'class_weight': [None, 'balanced'], # Class weights\n}\n\n# Create RandomizedSearchCV object\nrand_search = RandomizedSearchCV(estimator=svm_model, param_distributions=param_dist, cv=5, scoring='f1_macro', n_jobs=4)\n\n# Fit the model to the training data\nrand_search.fit(X_train_scaled, y_train)\n\n# Print the best hyperparameters\nprint(\"Best Hyperparameters:\", rand_search.best_params_)\n# Evaluate the model on the test set\nbest_svm_model = rand_search.best_estimator_\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T14:10:01.665215Z","iopub.execute_input":"2023-11-20T14:10:01.665963Z","iopub.status.idle":"2023-11-20T14:10:21.832119Z","shell.execute_reply.started":"2023-11-20T14:10:01.665920Z","shell.execute_reply":"2023-11-20T14:10:21.830536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test set\ny_pred_svm = best_svm_model.predict(X_test_scaled)\n# Compute the F1 score\nf1 = f1_score(y_valid, y_pred_svm, average= 'macro')\n\n# Print the F1 score\nprint(f1)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T14:11:16.500180Z","iopub.execute_input":"2023-11-20T14:11:16.501279Z","iopub.status.idle":"2023-11-20T14:11:17.041771Z","shell.execute_reply.started":"2023-11-20T14:11:16.501232Z","shell.execute_reply":"2023-11-20T14:11:17.040414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create AdaBoostClassifier with DecisionTree base estimator\nbase_estimator = DecisionTreeClassifier(max_depth=50)\nada_model = AdaBoostClassifier(estimator=base_estimator, random_state=42)\n\n# Define hyperparameter space for RandomizedSearchCV\nparam_dist = {\n    'n_estimators': randint(50, 200),  # Number of estimators\n    'learning_rate': [0.01, 0.1, 0.5, 1.0],  # Learning rate\n}\n\n# Create RandomizedSearchCV object\nrandom_search = RandomizedSearchCV(estimator=ada_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='f1_macro', random_state=42, n_jobs=4)\n\n# Fit the RandomizedSearchCV to the training data\nrandom_search.fit(X_train, y_train)\n\n# Get the best model from RandomizedSearchCV\nbest_ada_model = random_search.best_estimator_\n\n# Make predictions on the test set using the best model\ny_pred = best_ada_model.predict(X_valid)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T14:39:32.664121Z","iopub.execute_input":"2023-11-20T14:39:32.664578Z","iopub.status.idle":"2023-11-20T14:39:34.637196Z","shell.execute_reply.started":"2023-11-20T14:39:32.664541Z","shell.execute_reply":"2023-11-20T14:39:34.635959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the F1 score\nf1 = f1_score(y_valid, y_pred, average= 'macro')\n\n# Print the F1 score\nprint(f1)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T14:39:40.200820Z","iopub.execute_input":"2023-11-20T14:39:40.201258Z","iopub.status.idle":"2023-11-20T14:39:40.224645Z","shell.execute_reply.started":"2023-11-20T14:39:40.201226Z","shell.execute_reply":"2023-11-20T14:39:40.222971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:24:21.569842Z","iopub.execute_input":"2023-11-20T16:24:21.570289Z","iopub.status.idle":"2023-11-20T16:24:21.589823Z","shell.execute_reply.started":"2023-11-20T16:24:21.570254Z","shell.execute_reply":"2023-11-20T16:24:21.588369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Deep Neural Networks\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nimport pandas as pd\n\n# Encoding the target attribute for multi-class classification\nle = LabelEncoder().fit(y)\ny_enc = le.transform(y)\n\n# Split the data into training and testing sets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y_enc, test_size=0.2, random_state=42)\n\n# Normalize/Scale the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_valid = scaler.transform(X_valid)\n\n# Build the neural network model using Keras\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=(17,), kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n    tf.keras.layers.Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n    tf.keras.layers.Dense(len(le.classes_), activation='softmax')  # Multi-class, so using 'softmax'\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:25:24.036738Z","iopub.execute_input":"2023-11-20T16:25:24.037281Z","iopub.status.idle":"2023-11-20T16:25:24.127952Z","shell.execute_reply.started":"2023-11-20T16:25:24.037234Z","shell.execute_reply":"2023-11-20T16:25:24.126501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=64, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:25:53.025730Z","iopub.execute_input":"2023-11-20T16:25:53.026193Z","iopub.status.idle":"2023-11-20T16:26:07.336826Z","shell.execute_reply.started":"2023-11-20T16:25:53.026160Z","shell.execute_reply":"2023-11-20T16:26:07.335407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on test data\nloss, accuracy = model.evaluate(X_valid, y_valid)\nprint(f\"Test accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:26:10.614909Z","iopub.execute_input":"2023-11-20T16:26:10.615380Z","iopub.status.idle":"2023-11-20T16:26:55.478425Z","shell.execute_reply.started":"2023-11-20T16:26:10.615315Z","shell.execute_reply":"2023-11-20T16:26:55.476706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get predictions on the test set\ny_pred_probs = model.predict(X_valid)\n\n# Convert probabilities to class labels\ny_pred_indices = np.argmax(y_pred_probs, axis=1)\n\n# Inverse transform the predicted indices to original labels\ndecoded_labels = le.inverse_transform(y_pred_indices)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:02:53.167197Z","iopub.execute_input":"2023-11-20T16:02:53.168520Z","iopub.status.idle":"2023-11-20T16:02:53.332639Z","shell.execute_reply.started":"2023-11-20T16:02:53.168476Z","shell.execute_reply":"2023-11-20T16:02:53.331227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 'decoded_labels' now contains the original labels predicted by the model\nprint(decoded_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:02:55.522059Z","iopub.execute_input":"2023-11-20T16:02:55.523104Z","iopub.status.idle":"2023-11-20T16:02:55.535046Z","shell.execute_reply.started":"2023-11-20T16:02:55.523061Z","shell.execute_reply":"2023-11-20T16:02:55.532455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test data preparation\n\ntest_data = \"/kaggle/input/projetdm-data/TEST.CSV\"\n### Loop the data lines\nwith open(test_data, 'r') as temp_f:\n    # get No of columns in each line\n    col_count = [ len(l.split(\",\")) for l in temp_f.readlines() ]\n\n### Generate column names  (names will be 0, 1, 2, ..., maximum columns - 1)\ncolumn_names = [i for i in range(0, max(col_count))]\ndf_test = pd.read_csv(test_data,header=None, delimiter=\",\", names=column_names, low_memory=False).astype(str)\ndf_test.insert(0, '0', 0)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:33:24.646370Z","iopub.execute_input":"2023-11-22T15:33:24.647124Z","iopub.status.idle":"2023-11-22T15:33:25.492375Z","shell.execute_reply.started":"2023-11-22T15:33:24.647092Z","shell.execute_reply":"2023-11-22T15:33:25.490703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"converted_test_data = df_test.values\noutput_test_data = extract_features(converted_test_data, is_test = True)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:39:45.707088Z","iopub.execute_input":"2023-11-22T15:39:45.707435Z","iopub.status.idle":"2023-11-22T15:39:50.584688Z","shell.execute_reply.started":"2023-11-22T15:39:45.707410Z","shell.execute_reply":"2023-11-22T15:39:50.583077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_test_df = pd.DataFrame(output_test_data, columns=headers)\n# One-hot encode the specified columns\nnew_test_df = pd.get_dummies(new_test_df, columns=['race'])\nX_test = new_test_df.iloc[:, 1:]  # Features (game information)\npredictions = optimal_rf_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:40:24.213066Z","iopub.execute_input":"2023-11-22T15:40:24.213445Z","iopub.status.idle":"2023-11-22T15:40:24.257865Z","shell.execute_reply.started":"2023-11-22T15:40:24.213418Z","shell.execute_reply":"2023-11-22T15:40:24.256585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(new_test_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:15:23.144605Z","iopub.execute_input":"2023-11-20T16:15:23.145031Z","iopub.status.idle":"2023-11-20T16:15:23.152106Z","shell.execute_reply.started":"2023-11-20T16:15:23.144999Z","shell.execute_reply":"2023-11-20T16:15:23.150969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert probabilities to class labels\ny_pred_indices = np.argmax(predictions, axis=1)\n\n# Inverse transform the predicted indices to original labels\ndecoded_labels = le.inverse_transform(y_pred_indices)\nprint(len(decoded_labels))","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:15:25.790804Z","iopub.execute_input":"2023-11-20T16:15:25.791839Z","iopub.status.idle":"2023-11-20T16:15:25.799826Z","shell.execute_reply.started":"2023-11-20T16:15:25.791799Z","shell.execute_reply":"2023-11-20T16:15:25.798387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert predictions to a DataFrame\nsubmission_df = pd.DataFrame({'prediction': predictions})\nsubmission_df['RowId'] = submission_df.index + 1 # Adding row IDs starting from 0\n\n# Reorder the columns with 'RowID' as the first column\nsubmission_df = submission_df[['RowId', 'prediction']]\n\n\n# Save the DataFrame to a CSV file named 'submissions.csv'\nsubmission_df.to_csv('submissions.csv', index=False)  ","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:40:50.230976Z","iopub.execute_input":"2023-11-22T15:40:50.231358Z","iopub.status.idle":"2023-11-22T15:40:50.244547Z","shell.execute_reply.started":"2023-11-22T15:40:50.231330Z","shell.execute_reply":"2023-11-22T15:40:50.243490Z"},"trusted":true},"execution_count":null,"outputs":[]}]}