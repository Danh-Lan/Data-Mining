{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-13T17:04:21.568509Z","iopub.execute_input":"2023-11-13T17:04:21.568892Z","iopub.status.idle":"2023-11-13T17:04:21.579467Z","shell.execute_reply.started":"2023-11-13T17:04:21.568862Z","shell.execute_reply":"2023-11-13T17:04:21.578566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = \"/kaggle/input/projetdm-data/TRAIN.CSV\"\n### Loop the data lines\nwith open(train_data, 'r') as temp_f:\n    # get No of columns in each line\n    col_count = [ len(l.split(\",\")) for l in temp_f.readlines() ]\n\n### Generate column names  (names will be 0, 1, 2, ..., maximum columns - 1)\ncolumn_names = [i for i in range(0, max(col_count))]\ndf_train = pd.read_csv(train_data,header=None, delimiter=\",\", names=column_names, low_memory=False).astype(str)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-13T18:18:32.594088Z","iopub.execute_input":"2023-11-13T18:18:32.594451Z","iopub.status.idle":"2023-11-13T18:18:43.657609Z","shell.execute_reply.started":"2023-11-13T18:18:32.594426Z","shell.execute_reply":"2023-11-13T18:18:43.656540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nactions_to_count = [\"0\",\"1\",\"2\"]\nhotkeys_to_count = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]","metadata":{"execution":{"iopub.status.busy":"2023-11-13T18:10:57.362834Z","iopub.execute_input":"2023-11-13T18:10:57.363244Z","iopub.status.idle":"2023-11-13T18:13:13.651018Z","shell.execute_reply.started":"2023-11-13T18:10:57.363213Z","shell.execute_reply":"2023-11-13T18:13:13.650180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_features(input_data):\n    output_data = []\n    for row in input_data:\n        count_actions = [0] * len(actions_to_count)\n        count_hotkeys = [0] * len(hotkeys_to_count)\n        new_row = []\n        new_row.append(row[0])\n        new_row.append(row[1])\n        number = -1\n        hasBase = False\n        for action in row[2:]:\n            # count 0, 1, 2 at the end of \"hotkey\"\n            for index, substring in enumerate(actions_to_count):\n                if (action.startswith('hotkey') and action.endswith(substring)):\n                    count_actions[index] += 1\n\n            # count hotkey\n            for index, substring in enumerate(hotkeys_to_count):\n                if (action.startswith('hotkey') and action[-2] == substring):\n                    count_hotkeys[index] += 1\n\n            # find the nearest following moment of Base\n            if (action == \"Base\"):\n                hasBase = True\n            if (hasBase and number == -1):\n                if isinstance(action, str):\n                    match = re.match(r't(\\d+)', action)\n                    if match:\n                        number = int(match.group(1))\n\n        new_row.append(number)\n        for i in range(len(count_actions)):\n            new_row.append(count_actions[i])\n        for i in range(len(count_hotkeys)):\n            new_row.append(count_hotkeys[i])\n        output_data.append(new_row)\n    return output_data\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-13T18:27:08.689545Z","iopub.execute_input":"2023-11-13T18:27:08.690383Z","iopub.status.idle":"2023-11-13T18:27:08.700325Z","shell.execute_reply.started":"2023-11-13T18:27:08.690349Z","shell.execute_reply":"2023-11-13T18:27:08.699468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"converted_train_data = df_train.values\noutput_train_data = extract_features(converted_train_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the table to a DataFrame with headers\nheaders = ['url', 'race', 'first_base_time', 'number_hotkey_created', 'number_hotkey_update', 'number_hotkey_used',\n          'number_key0','number_key1', 'number_key2', 'number_key3', 'number_key4', 'number_key5', 'number_key6',\n          'number_key7', 'number_key8', 'number_key9']\nnew_df = pd.DataFrame(output_train_data, columns=headers)\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-13T18:14:57.355470Z","iopub.execute_input":"2023-11-13T18:14:57.355934Z","iopub.status.idle":"2023-11-13T18:14:57.394982Z","shell.execute_reply.started":"2023-11-13T18:14:57.355901Z","shell.execute_reply":"2023-11-13T18:14:57.394085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One-hot encode the specified columns\nnew_df = pd.get_dummies(new_df, columns=['race'])\n\n# Display the encoded DataFrame\nprint(new_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-13T18:15:21.976631Z","iopub.execute_input":"2023-11-13T18:15:21.977542Z","iopub.status.idle":"2023-11-13T18:15:21.993944Z","shell.execute_reply.started":"2023-11-13T18:15:21.977508Z","shell.execute_reply":"2023-11-13T18:15:21.992738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train/ Test split\nfrom sklearn.model_selection import train_test_split\nX = new_df.iloc[:, 1:]  # Features (game information)\ny = new_df.iloc[:, 0]   # Target variable (player's URL)\n\n# Split the data into training and testing sets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)  # You can adjust the test_size\n","metadata":{"execution":{"iopub.status.busy":"2023-11-13T18:17:06.214715Z","iopub.execute_input":"2023-11-13T18:17:06.215593Z","iopub.status.idle":"2023-11-13T18:17:06.224545Z","shell.execute_reply.started":"2023-11-13T18:17:06.215560Z","shell.execute_reply":"2023-11-13T18:17:06.223443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest model training\n# Initialize the Random Forest model\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=100)  # You can adjust the number of trees (n_estimators)\n\n# For regression problems, use RandomForestRegressor and set the appropriate parameters\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Predict using the test set\npredictions = model.predict(X_valid)\n\n# Evaluate the model (if needed)\n# For classification problems:\naccuracy = model.score(X_valid, y_valid)\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-13T18:17:08.590462Z","iopub.execute_input":"2023-11-13T18:17:08.591378Z","iopub.status.idle":"2023-11-13T18:17:10.446805Z","shell.execute_reply.started":"2023-11-13T18:17:08.591342Z","shell.execute_reply":"2023-11-13T18:17:10.445887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test data preparation\n\ntest_data = \"/kaggle/input/projetdm-data/TEST.CSV\"\n### Loop the data lines\nwith open(test_data, 'r') as temp_f:\n    # get No of columns in each line\n    col_count = [ len(l.split(\",\")) for l in temp_f.readlines() ]\n\n### Generate column names  (names will be 0, 1, 2, ..., maximum columns - 1)\ncolumn_names = [i for i in range(0, max(col_count))]\ndf_test = pd.read_csv(test_data,header=None, delimiter=\",\", names=column_names, low_memory=False).astype(str)\ndf_test.insert(0, '0', 0)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-13T18:34:14.142326Z","iopub.execute_input":"2023-11-13T18:34:14.143097Z","iopub.status.idle":"2023-11-13T18:34:15.305442Z","shell.execute_reply.started":"2023-11-13T18:34:14.143052Z","shell.execute_reply":"2023-11-13T18:34:15.304504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"converted_test_data = df_test.values\noutput_test_data = extract_features(converted_test_data)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-13T18:34:57.488721Z","iopub.execute_input":"2023-11-13T18:34:57.489514Z","iopub.status.idle":"2023-11-13T18:35:05.962291Z","shell.execute_reply.started":"2023-11-13T18:34:57.489481Z","shell.execute_reply":"2023-11-13T18:35:05.961293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_test_df = pd.DataFrame(output_test_data, columns=headers)\nnew_test_df = pd.get_dummies(new_test_df, columns=['race'])\nX_test = new_test_df.iloc[:, 1:]  # Features (game information)\npredictions = model.predict(X_test)\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T18:37:17.956664Z","iopub.execute_input":"2023-11-13T18:37:17.957525Z","iopub.status.idle":"2023-11-13T18:37:18.014971Z","shell.execute_reply.started":"2023-11-13T18:37:17.957491Z","shell.execute_reply":"2023-11-13T18:37:18.014066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert predictions to a DataFrame\nsubmission_df = pd.DataFrame({'prediction': predictions})\nsubmission_df['RowID'] = submission_df.index + 1 # Adding row IDs starting from 0\n\n# Reorder the columns with 'RowID' as the first column\nsubmission_df = submission_df[['RowID', 'prediction']]\n\n\n# Save the DataFrame to a CSV file named 'submissions.csv'\nsubmission_df.to_csv('submissions.csv', index=False)  ","metadata":{"execution":{"iopub.status.busy":"2023-11-13T18:41:36.741244Z","iopub.execute_input":"2023-11-13T18:41:36.741969Z","iopub.status.idle":"2023-11-13T18:41:36.751871Z","shell.execute_reply.started":"2023-11-13T18:41:36.741936Z","shell.execute_reply":"2023-11-13T18:41:36.751011Z"},"trusted":true},"execution_count":null,"outputs":[]}]}